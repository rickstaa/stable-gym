:py:mod:`stable_gym.envs.classic_control`
=========================================

.. py:module:: stable_gym.envs.classic_control

.. autoapi-nested-parse::

   Stable Gym gymnasium environments based on classical control problems or
   `classical control`_ environments found in the :gymnasium:`gymnasium <>` library.

   .. _`classical control`: https://gymnasium.farama.org/environments/classic_control



Subpackages
-----------
.. toctree::
   :titlesonly:
   :maxdepth: 3

   cartpole_cost/index.rst
   cartpole_tracking_cost/index.rst
   ex3_ekf/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   stable_gym.envs.classic_control.CartPoleCost
   stable_gym.envs.classic_control.CartPoleTrackingCost
   stable_gym.envs.classic_control.Ex3EKF




.. py:class:: CartPoleCost(render_mode=None, max_cost=100.0, clip_action=True, action_space_dtype=np.float64, observation_space_dtype=np.float64)


   Bases: :py:obj:`gymnasium.Env`

   Custom CartPole Gymnasium environment.

   .. note::
       This environment can be used in a vectorized manner. Refer to the
       :gymnasium:`gym.vector <api/vector>` documentation for details.

   .. attention::
       If you're using this environment to reproduce the results of `Han et al.`_
       (2020), please note that slight differences may occur due to the
       modifications mentioned below. For an accurate reproduction, refer to the
       separate ``han2020`` branch, which mirrors the environment used in their
       study. It can be accessed `here <here_branch_>`_.

   Source:
       This environment is a modified version of the CartPole environment from the
       Farma Foundation's :gymnasium:`Gymnasium <>` package, first used by `Han et al.`_
       in 2020. Modifications made by Han et al. include:

           - The action space is **continuous**, contrasting with the original **discrete**
             setting.
           - Offers an optional feature to confine actions within the defined action space,
             preventing the agent from exceeding set boundaries when activated.
           - The **reward** function is replaced with a (positive definite) **cost**
             function (negated reward), in line with Lyapunov stability theory.
           - Maximum cart force is increased from ``10`` to ``20``.
           - Episode length is reduced from ``500`` to ``250``.
           - A termination cost of :math:`c=100` is introduced for early episode
             termination, to promote cost minimization.
           - The terminal angle limit is expanded from the original ``12`` degrees to
             ``20`` degrees, enhancing recovery potential.
           - The terminal position limit is extended from ``2.4`` meters to ``10``
             meters, broadening the recovery range.
           - Velocity limits are adjusted from :math:`\pm \infty` to :math:`\pm 50`,
             accelerating training.
           - Angular velocity termination threshold is lowered from :math:`\pm \infty`
             to :math:`\pm 50`, likely for improved training efficiency.
           - Random initial state range is modified from ``[-0.05, 0.05]`` to ``[-5, 5]``
             for the cart position and ``[-0.2, 0.2]`` for all other states, allowing
             for expanded exploration.
           - The info dictionary is expanded to include the reference state, state of
             interest, and reference error.

       Additional modifications in our implementation:

           - Unlike the original environment's fixed cost threshold of ``100``, this
             version allows users to adjust the maximum cost threshold via the
             :obj:`max_cost` input, improving training adaptability.
           - The gravity constant is adjusted back from ``10`` to the real-world value
             of ``9.8``, aligning it closer with the original CartPole environment.
           - The data types for action and observation spaces are set to ``np.float64``,
             diverging from the ``np.float32`` used by Han et al. 2020. This aligns
             the Gymnasium implementation with the original CartPole environment.

   Observation:
       **Type**: Box(4) or Box(6)

       +-----+------------------------------+-----------------------+---------------------+
       | Num | Observation                  | Min                   | Max                 |
       +=====+==============================+=======================+=====================+
       | 0   | Cart Position                | -20                   | 20                  |
       +-----+------------------------------+-----------------------+---------------------+
       | 1   | Cart Velocity                | -50                   | 50                  |
       +-----+------------------------------+-----------------------+---------------------+
       | 2   | Pole Angle                   | ~ -.698 rad (-40 deg) | ~ .698 rad (40 deg) |
       +-----+------------------------------+-----------------------+---------------------+
       | 3   | Pole Angular Velocity        | -50rad                | 50rad               |
       +-----+------------------------------+-----------------------+---------------------+

       .. note::
           While the ranges above denote the possible values for observation space of
           each element, it is not reflective of the allowed values of the state space
           in an un-terminated episode. Particularly:

               -   The cart x-position (index 0) can be take values between
                   ``(-20, 20)``, but the episode terminates if the cart leaves the
                   ``(-10, 10)`` range.
               -   The pole angle can be observed between  ``(-0.698, .698)`` radians
                   (or **±40°**), but the episode terminates if the pole angle is not
                   in  the range ``(-.349, .349)`` (or **±20°**)

   Actions:
       **Type**: Box(1)

       +-----+----------------------+-----------------------+---------------------+
       | Num | Action               | Min                   | Max                 |
       +=====+======================+=======================+=====================+
       | 0   | The controller Force | -20                   | 20                  |
       +-----+----------------------+-----------------------+---------------------+

       .. note::
           The velocity that is reduced or increased by the applied force is not fixed
           and it depends on the angle the pole is pointing. The center of gravity of
           the pole varies the amount of energy needed to move the cart underneath it.

   Cost:
       A cost, computed using the :meth:`CartPoleCost.cost` method, is given for each
       simulation step, including the terminal step. This cost is the error
       between the cart position and angle and the zero position and angle. The cost
       is set to the maximum cost when the episode is terminated.The cost is defined as:

       .. math::

           cost = (x / x_{threshold})^2 + 20 * (\theta / \theta_{threshold})^2

   Starting State:
       The position is assigned a random value in ``[-5,5]`` and the other states are
       assigned a uniform random value in ``[-0.2..0.2]``.

   Episode Termination:
       -   Pole Angle is more than 20 degrees.
       -   Cart Position is more than 10 m (center of the cart reaches the edge of the
           display).
       -   Episode length is greater than 200.
       -   The cost is greater than a threshold (100 by default). This threshold can
           be changed using the ``max_cost`` environment argument.

   Solved Requirements:
       Considered solved when the average cost is less than or equal to 50 over
       100 consecutive trials.

   How to use:
       .. code-block:: python

           import stable_gym
           import gymnasium as gym
           env = gym.make("stable_gym:CartPoleCost-v1")

       On reset, the ``options`` parameter allows the user to change the bounds used to
       determine the new random state when ``random=True``.

   .. attribute:: state

      The current state.

      :type: numpy.ndarray

   .. attribute:: t

      Current time step.

      :type: float

   .. attribute:: tau

      The time step size. Also available as ``self.dt``.

      :type: float

   .. attribute:: target_pos

      The target position.

      :type: float

   .. attribute:: constraint_pos

      The constraint position.

      :type: float

   .. attribute:: kinematics_integrator

      The kinematics integrator used to update the state.
      Options are ``euler`` and ``semi-implicit euler``.

      :type: str

   .. attribute:: theta_threshold_radians

      The angle at which the pole is considered to be
      at a terminal state.

      :type: float

   .. attribute:: x_threshold

      The position at which the cart is considered to be at a
      terminal state.

      :type: float

   .. attribute:: max_v

      The maximum velocity of the cart.

      :type: float

   .. attribute:: max_w

      The maximum angular velocity of the pole.

      :type: float

   .. attribute:: max_cost

      The maximum cost.

      :type: float

   .. _`Neuronlike Adaptive Elements That Can Solve Difficult Learning Control Problem`: https://ieeexplore.ieee.org/document/6313077
   .. _`Han et al.`: https://arxiv.org/abs/2004.14288
   .. _`here_branch`: https://github.com/rickstaa/stable-gym/tree/han2020

   Initialise a new CartPoleCost environment instance.

   :param render_mode: Gym rendering mode. By default ``None``.
   :type render_mode: str, optional
   :param max_cost: The maximum cost allowed before the episode is
                    terminated. Defaults to ``100.0``.
   :type max_cost: float, optional
   :param clip_action: Whether the actions should be clipped if
                       they are greater than the set action limit. Defaults to ``True``.
   :type clip_action: str, optional
   :param action_space_dtype: The data type of the
                              action space. Defaults to ``np.float64``.
   :type action_space_dtype: union[numpy.dtype, str], optional
   :param observation_space_dtype: The data type
                                   of the observation space. Defaults to ``np.float64``.
   :type observation_space_dtype: union[numpy.dtype, str], optional

   .. py:property:: total_mass

      Property that returns the full mass of the system.

   .. py:property:: _com_length

      Property that returns the position of the center of mass.

   .. py:property:: polemass_length

      Property that returns the pole mass times the COM length.

   .. py:property:: pole_mass_length

      Alias for :attr:`polemass_length`.

   .. py:property:: mass_pole

      Alias for :attr:`masspole`.

   .. py:property:: mass_cart

      Alias for :attr:`masscart`.

   .. py:property:: dt

      Property that also makes the timestep available under the :attr:`dt`
      attribute.

   .. py:property:: physics_time

      Returns the physics time. Alias for :attr:`.t`.

   .. py:attribute:: metadata

      

   .. py:method:: set_params(length, mass_of_cart, mass_of_pole, gravity)

      Sets the most important system parameters.

      :param length: The pole length.
      :type length: float
      :param mass_of_cart: Cart mass.
      :type mass_of_cart: float
      :param mass_of_pole: Pole mass.
      :type mass_of_pole: float
      :param gravity: The gravity constant.
      :type gravity: float


   .. py:method:: get_params()

      Retrieves the most important system parameters.

      :returns:

                tuple containing:

                    -   length(:obj:`float`): The pole length.
                    -   pole_mass (:obj:`float`): The pole mass.
                    -   pole_mass (:obj:`float`): The cart mass.
                    -   gravity (:obj:`float`): The gravity constant.
      :rtype: (tuple)


   .. py:method:: reset_params()

      Resets the most important system parameters.


   .. py:method:: cost(x, theta)

      Returns the cost for a given cart position (x) and a pole angle (theta).

          Args:
              x (float): The current cart position.
              theta (float): The current pole angle (rads).

      :returns:

                tuple containing:

                    -   cost (float): The current cost.
      :rtype: (tuple)


   .. py:method:: step(action)

      Take step into the environment.

      :param action: The action we want to perform in the environment.
      :type action: numpy.ndarray

      :returns:

                tuple containing:

                    -   obs (:obj:`np.ndarray`): Environment observation.
                    -   cost (:obj:`float`): Cost of the action.
                    -   terminated (:obj:`bool`): Whether the episode is terminated.
                    -   truncated (:obj:`bool`): Whether the episode was truncated. This
                        value is set by wrappers when for example a time limit is reached or
                        the agent goes out of bounds.
                    -   info (:obj:`dict`): Additional information about the environment.
      :rtype: (tuple)


   .. py:method:: reset(seed=None, options=None, random=True)

      Reset gymnasium environment.

      :param seed: A random seed for the environment. By default
                   ``None``.
      :type seed: int, optional
      :param options: A dictionary containing additional options for
                      resetting the environment. By default ``None``. Not used in this
                      environment.
      :type options: dict, optional
      :param random: Whether we want to randomly initialise the
                     environment. By default True.
      :type random: bool, optional

      :returns:

                tuple containing:

                    -   obs (:obj:`numpy.ndarray`): Initial environment observation.
                    -   info (:obj:`dict`): Dictionary containing additional information.
      :rtype: (tuple)


   .. py:method:: render()

      Render one frame of the environment.


   .. py:method:: close()

      Close down the viewer



.. py:class:: CartPoleTrackingCost(render_mode=None, reference_target_position=0.0, reference_amplitude=7.0, reference_frequency=0.005, max_cost=100.0, clip_action=True, exclude_reference_from_observation=False, exclude_reference_error_from_observation=True, action_space_dtype=np.float64, observation_space_dtype=np.float64)


   Bases: :py:obj:`gymnasium.Env`

   Custom CartPole Gymnasium environment.

   .. note::
       This environment can be used in a vectorized manner. Refer to the
       :gymnasium:`gym.vector <api/vector>` documentation for details.

   Source:
       This environment is a modified version of the CartPole environment from the
       Farma Foundation's :gymnasium:`Gymnasium <>` package, first used by `Han et al.`_
       in 2020. Modifications made by Han et al. include:

           - The action space is **continuous**, contrasting with the original **discrete**
             setting.
           - Offers an optional feature to confine actions within the defined action space,
             preventing the agent from exceeding set boundaries when activated.
           - The **reward** function is replaced with a (positive definite) **cost**
             function (negated reward), in line with Lyapunov stability theory. This cost is the difference between a state variable and a reference value (error).
           - Maximum cart force is increased from ``10`` to ``20``.
           - Episode length is reduced from ``500`` to ``250``.
           - A termination cost of :math:`c=100` is introduced for early episode
             termination, to promote cost minimization.
           - The terminal angle limit is expanded from the original ``12`` degrees to
             ``20`` degrees, enhancing recovery potential.
           - The terminal position limit is extended from ``2.4`` meters to ``10``
             meters, broadening the recovery range.
           - Velocity limits are adjusted from :math:`\pm \infty` to :math:`\pm 50`,
             accelerating training.
           - Angular velocity termination threshold is lowered from :math:`\pm \infty`
             to :math:`\pm 50`, likely for improved training efficiency.
           - Random initial state range is modified from ``[-0.05, 0.05]`` to ``[-5, 5]``
             for the cart position and ``[-0.2, 0.2]`` for all other states, allowing
             for expanded exploration.

       Additional modifications in our implementation:

           - Unlike the original environment's fixed cost threshold of ``100``, this
             version allows users to adjust the maximum cost threshold via the
             :obj:`max_cost` input, improving training adaptability.
           - The gravity constant is adjusted back from ``10`` to the real-world value
             of ``9.8``, aligning it closer with the original CartPole environment.
           - The stabilization objective is replaced with a **reference tracking task**
             for enhanced control.
           - Two additional observations are introduced, facilitating
             **reference tracking**.
           - The info dictionary now provides **extra information** about the reference
             to be tracked.
           - The data types for action and observation spaces are set to ``np.float64``,
             diverging from the ``np.float32`` used by Han et al. 2020. This aligns
             the Gymnasium implementation with the original CartPole environment.

   Observation:
       **Type**: Box(4) or Box(6)

       +-----+-------------------------------+-----------------------+---------------------+
       | Num | Observation                   | Min                   | Max                 |
       +=====+===============================+=======================+=====================+
       | 0   | Cart Position                 | -20                   | 20                  |
       +-----+-------------------------------+-----------------------+---------------------+
       | 1   | Cart Velocity                 | -50                   | 50                  |
       +-----+-------------------------------+-----------------------+---------------------+
       | 2   | Pole Angle                    | ~ -.698 rad (-40 deg) | ~ .698 rad (40 deg) |
       +-----+-------------------------------+-----------------------+---------------------+
       | 3   | Pole Angular Velocity         | -50rad                | 50rad               |
       +-----+-------------------------------+-----------------------+---------------------+
       | 4   | The cart position reference   | -20                   | 20                  |
       +-----+-------------------------------+-----------------------+---------------------+
       | (5) || **Optional** - The reference | -20                   | 20                  |
       |     || tracking error               |                       |                     |
       +-----+-------------------------------+-----------------------+---------------------+

       .. note::
           While the ranges above denote the possible values for observation space of
           each element, it is not reflective of the allowed values of the state space
           in an un-terminated episode. Particularly:

               -   The cart x-position (index 0) can be take values between
                   ``(-20, 20)``, but the episode terminates if the cart leaves the
                   ``(-10, 10)`` range.
               -   The pole angle can be observed between  ``(-0.698, .698)`` radians
                   (or **±40°**), but the episode terminates if the pole angle is not
                   in  the range ``(-.349, .349)`` (or **±20°**)

   Actions:
       **Type**: Box(1)

       +-----+----------------------+-----------------------+---------------------+
       | Num | Action               | Min                   | Max                 |
       +=====+======================+=======================+=====================+
       | 0   | The controller Force | -20                   | 20                  |
       +-----+----------------------+-----------------------+---------------------+

       .. note::
           The velocity that is reduced or increased by the applied force is not fixed
           and it depends on the angle the pole is pointing. The center of gravity of
           the pole varies the amount of energy needed to move the cart underneath it.

   Cost:
       A cost, computed using the :meth:`CartPoleTrackingCost.cost` method, is given for each
       simulation step, including the terminal step. This cost is defined as a error
       between a state variable and a reference value. The cost is set to the maximum
       cost when the episode is terminated. The cost is defined as:

       .. math::

           cost = (x - x_{ref})^2 + (\theta / \theta_{threshold})^2

   Starting State:
       The position is assigned a random value in ``[-5,5]`` and the other states are
       assigned a uniform random value in ``[-0.2..0.2]``.

   Episode Termination:
       -   Pole Angle is more than 60 degrees.
       -   Cart Position is more than 10 m (center of the cart reaches the edge of the
           display).
       -   Episode length is greater than 200.
       -   The cost is greater than a threshold (100 by default). This threshold can
           be changed using the ``max_cost`` environment argument.

   Solved Requirements:
       Considered solved when the average cost is less than or equal to 50 over
       100 consecutive trials.

   How to use:
       .. code-block:: python

           import stable_gym
           import gymnasium as gym
           env = gym.make("stable_gym:CartPoleTrackingCost-v1")

       On reset, the ``options`` parameter allows the user to change the bounds used to
       determine the new random state when ``random=True``.

   .. attribute:: state

      The current state.

      :type: numpy.ndarray

   .. attribute:: t

      Current time step.

      :type: float

   .. attribute:: tau

      The time step size. Also available as ``self.dt``.

      :type: float

   .. attribute:: target_pos

      The target position.

      :type: float

   .. attribute:: constraint_pos

      The constraint position.

      :type: float

   .. attribute:: kinematics_integrator

      The kinematics integrator used to update the state.
      Options are ``euler`` and ``semi-implicit euler``.

      :type: str

   .. attribute:: theta_threshold_radians

      The angle at which the pole is considered to be
      at a terminal state.

      :type: float

   .. attribute:: x_threshold

      The position at which the cart is considered to be at a
      terminal state.

      :type: float

   .. attribute:: max_v

      The maximum velocity of the cart.

      :type: float

   .. attribute:: max_w

      The maximum angular velocity of the pole.

      :type: float

   .. attribute:: max_cost

      The maximum cost.

      :type: float

   .. _`Neuronlike Adaptive Elements That Can Solve Difficult Learning Control Problem`: https://ieeexplore.ieee.org/document/6313077
   .. _`Han et al.`: https://arxiv.org/abs/2004.14288

   Initialise a new CartPoleTrackingCost environment instance.

   :param render_mode: Gym rendering mode. By default ``None``.
   :type render_mode: str, optional
   :param reference_target_position: The reference target position, by default
                                     ``0.0`` (i.e. the mean of the reference signal).
   :param reference_amplitude: The reference amplitude, by default ``7.0``.
   :param reference_frequency: The reference frequency, by default ``0.005``.
   :param max_cost: The maximum cost allowed before the episode is
                    terminated. Defaults to ``100.0``.
   :type max_cost: float, optional
   :param clip_action: Whether the actions should be clipped if
                       they are greater than the set action limit. Defaults to ``True``.
   :type clip_action: str, optional
   :param exclude_reference_from_observation: Whether the reference
                                              should be excluded from the observation. Defaults to ``False``.
   :type exclude_reference_from_observation: bool, optional
   :param exclude_reference_error_from_observation: Whether the error
                                                    should be excluded from the observation. Defaults to ``True``.
   :type exclude_reference_error_from_observation: bool, optional
   :param action_space_dtype: The data type of the
                              action space. Defaults to ``np.float64``.
   :type action_space_dtype: union[numpy.dtype, str], optional
   :param observation_space_dtype: The data type
                                   of the observation space. Defaults to ``np.float64``.
   :type observation_space_dtype: union[numpy.dtype, str], optional

   .. py:property:: total_mass

      Property that returns the full mass of the system.

   .. py:property:: _com_length

      Property that returns the position of the center of mass.

   .. py:property:: polemass_length

      Property that returns the pole mass times the COM length.

   .. py:property:: pole_mass_length

      Alias for :attr:`polemass_length`.

   .. py:property:: mass_pole

      Alias for :attr:`masspole`.

   .. py:property:: mass_cart

      Alias for :attr:`masscart`.

   .. py:property:: dt

      Property that also makes the timestep available under the :attr:`dt`
      attribute.

   .. py:property:: physics_time

      Returns the physics time. Alias for :attr:`.t`.

   .. py:attribute:: metadata

      

   .. py:method:: set_params(length, mass_of_cart, mass_of_pole, gravity)

      Sets the most important system parameters.

      :param length: The pole length.
      :type length: float
      :param mass_of_cart: Cart mass.
      :type mass_of_cart: float
      :param mass_of_pole: Pole mass.
      :type mass_of_pole: float
      :param gravity: The gravity constant.
      :type gravity: float


   .. py:method:: get_params()

      Retrieves the most important system parameters.

      :returns:

                tuple containing:

                    -   length(:obj:`float`): The pole length.
                    -   pole_mass (:obj:`float`): The pole mass.
                    -   pole_mass (:obj:`float`): The cart mass.
                    -   gravity (:obj:`float`): The gravity constant.
      :rtype: (tuple)


   .. py:method:: reset_params()

      Resets the most important system parameters.


   .. py:method:: reference(t)

      Returns the current value of the periodic cart reference signal that is
      tracked by the cart-pole system.

      :param t: The current time step.
      :type t: float

      :returns: The current reference value.
      :rtype: float


   .. py:method:: cost(x, theta)

      Returns the cost for a given cart position (x) and a pole angle (theta).

          Args:
              x (float): The current cart position.
              theta (float): The current pole angle (rads).

      :returns:

                tuple containing:

                    -   cost (float): The current cost.
                    -   r_1 (float): The current position reference.
      :rtype: (tuple)


   .. py:method:: step(action)

      Take step into the environment.

      :param action: The action we want to perform in the environment.
      :type action: numpy.ndarray

      :returns:

                tuple containing:

                    -   obs (:obj:`np.ndarray`): Environment observation.
                    -   cost (:obj:`float`): Cost of the action.
                    -   terminated (:obj:`bool`): Whether the episode is terminated.
                    -   truncated (:obj:`bool`): Whether the episode was truncated. This
                        value is set by wrappers when for example a time limit is reached or
                        the agent goes out of bounds.
                    -   info (:obj:`dict`): Additional information about the environment.
      :rtype: (tuple)


   .. py:method:: reset(seed=None, options=None, random=True)

      Reset gymnasium environment.

      :param seed: A random seed for the environment. By default
                   ``None``.
      :type seed: int, optional
      :param options: A dictionary containing additional options for
                      resetting the environment. By default ``None``. Not used in this
                      environment.
      :type options: dict, optional
      :param random: Whether we want to randomly initialise the
                     environment. By default True.
      :type random: bool, optional

      :returns:

                tuple containing:

                    -   obs (:obj:`numpy.ndarray`): Initial environment observation.
                    -   info (:obj:`dict`): Dictionary containing additional information.
      :rtype: (tuple)


   .. py:method:: render()

      Render one frame of the environment.


   .. py:method:: close()

      Close down the viewer



.. py:class:: Ex3EKF(render_mode=None, clipped_action=True)


   Bases: :py:obj:`gymnasium.Env`

   Noisy master slave system

   Description:
       The goal of the agent in the Ex3EKF environment is to act in such a way that
       estimator perfectly estimated the original noisy system. By doing this it serves
       as a RL based stationary Kalman filter. First presented by `Wu et al. 2023`_.

   Observation:
       **Type**: Box(4)

       +-----+------------------------+----------------------+--------------------+
       | Num | Observation            | Min                  | Max                |
       +=====+========================+======================+====================+
       | 0   | The estimated angle    | -10000 rad           | 10000 rad          |
       +-----+------------------------+----------------------+--------------------+
       | 1   | The estimated frequency| -10000 hz            | 10000 hz           |
       +-----+------------------------+----------------------+--------------------+
       | 2   | Actual angle           | -10000 rad           | 10000 rad          |
       +-----+------------------------+----------------------+--------------------+
       | 3   | Actual frequency       | -10000 rad           | 10000 rad          |
       +-----+------------------------+----------------------+--------------------+

   Actions:
       **Type**: Box(2)

       +-----+-----------------------------------------------+
       | Num | Action                                        |
       +=====+===============================================+
       | 0   | First action coming from the RL Kalman filter |
       +-----+-----------------------------------------------+
       | 1   | Second action coming from the RL Kalman filter|
       +-----+-----------------------------------------------+

   Cost:
       A cost, computed as the sum of the squared differences between the estimated and the actual states:

       .. math::

           C = {(\hat{x}_1 - x_1)}^2 + {(\hat{x}_2 - x_2)}^2

   Starting State:
       All observations are assigned a uniform random value in ``[-0.05..0.05]``

   Episode Termination:
       -   When the step cost is higher than 100.

   Solved Requirements:
       Considered solved when the average cost is lower than 300.

   .. attribute:: state

      The current system state.

      :type: numpy.ndarray

   .. attribute:: t

      The current time step.

      :type: float

   .. attribute:: dt

      The environment step size. Also available as :attr:`.tau`.

      :type: float

   .. attribute:: sigma

      The variance of the system noise.

      :type: float

   .. _`Wu et al. 2023`: https://www.sciencedirect.com/science/article/pii/S0005109823001528

   Initialise new Ex3EKF environment instance.

   :param render_mode: The render mode you want to use. Defaults to
                       ``None``. Not used in this environment.
   :type render_mode: str, optional
   :param clipped_action: Whether the actions should be clipped if
                          they are greater than the set action limit. Defaults to ``True``.
   :type clipped_action: str, optional

   .. py:property:: tau

      Alias for the environment step size. Done for compatibility with the
      other gymnasium environments.

   .. py:property:: physics_time

      Returns the physics time. Alias for :attr:`.t`.

   .. py:method:: step(action)

      Take step into the environment.

      :param action: The action we want to perform in the environment.
      :type action: numpy.ndarray

      :returns:

                tuple containing:

                    -   obs (:obj:`np.ndarray`): Environment observation.
                    -   cost (:obj:`float`): Cost of the action.
                    -   terminated (:obj:`bool`): Whether the episode is terminated.
                    -   truncated (:obj:`bool`): Whether the episode was truncated. This
                        value is set by wrappers when for example a time limit is reached or
                        the agent goes out of bounds.
                    -   info (:obj:`dict`): Additional information about the environment.
      :rtype: (tuple)


   .. py:method:: reset(seed=None, options=None)

      Reset gymnasium environment.

      :param seed: A random seed for the environment. By default
                   `None``.
      :type seed: int, optional
      :param options: A dictionary containing additional options for
                      resetting the environment. By default ``None``. Not used in this
                      environment.
      :type options: dict, optional

      :returns:

                tuple containing:

                    -   obs (:obj:`numpy.ndarray`): Initial environment observation.
                    -   info (:obj:`dict`): Dictionary containing additional information.
      :rtype: (tuple)


   .. py:method:: reference(x)

      Returns the current value of the periodic reference signal that is tracked by
      the Synthetic oscillatory network.

      :param x: The reference value.
      :type x: float

      :returns: The current reference value.
      :rtype: float


   .. py:method:: render(mode='human')
      :abstractmethod:

      Render one frame of the environment.

      :param mode: Gym rendering mode. The default mode will do something
                   human friendly, such as pop up a window.
      :type mode: str, optional

      :raises NotImplementedError: Will throw a NotImplimented error since the render
          method has not yet been implemented.

      .. note:: This currently is not yet implemented.



