:py:mod:`stable_gym.envs.mujoco.ant_cost.ant_cost`
==================================================

.. py:module:: stable_gym.envs.mujoco.ant_cost.ant_cost

.. autoapi-nested-parse::

   The AntCost gymnasium environment.



Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   stable_gym.envs.mujoco.ant_cost.ant_cost.AntCost




Attributes
~~~~~~~~~~

.. autoapisummary::

   stable_gym.envs.mujoco.ant_cost.ant_cost.EPISODES
   stable_gym.envs.mujoco.ant_cost.ant_cost.RANDOM_STEP
   stable_gym.envs.mujoco.ant_cost.ant_cost.env


.. py:data:: EPISODES
   :value: 10

   

.. py:data:: RANDOM_STEP
   :value: True

   

.. py:class:: AntCost(reference_forward_velocity=1.0, randomise_reference_forward_velocity=False, randomise_reference_forward_velocity_range=(0.5, 1.5), forward_velocity_weight=1.0, include_ctrl_cost=False, include_health_penalty=True, health_penalty_size=10, ctrl_cost_weight=0.0001, use_contact_forces=False, contact_cost_weight=0.0005, terminate_when_unhealthy=True, healthy_z_range=(0.2, 1.0), contact_force_range=(-1.0, 1.0), reset_noise_scale=0.1, exclude_current_positions_from_observation=True, exclude_reference_from_observation=False, exclude_reference_error_from_observation=True, exclude_x_velocity_from_observation=False, action_space_dtype=np.float32, observation_space_dtype=np.float64, **kwargs)


   Bases: :py:obj:`gymnasium.envs.mujoco.ant_v4.AntEnv`, :py:obj:`gymnasium.utils.EzPickle`

   Custom Ant gymnasium environment.

   .. note::
       Can also be used in a vectorized manner. See the
       :gymnasium:`gym.vector <api/vector>` documentation.

   Source:
       This is a modified version of the Ant Mujoco environment found in the
       :gymnasium:`gymnasium library <environments/mujoco/ant>`. This modification
       was first described by `Han et al. 2020 <https://arxiv.org/abs/2004.14288>`_.
       Compared to the original Ant environment in this modified version:

       -   The objective was changed to a velocity-tracking task. To do this, the reward
           is replaced with a cost. This cost is the squared difference between the
           Ant's forward velocity and a reference value (error). Additionally, also
           a control cost and health penalty can be included in the cost.
       -   Three **optional** variables were added to the observation space; The reference velocity, the reference error
           (i.e. the difference between the ant's forward velocity and the reference) and the ant's forward velocity.
           These variables can be enabled using the ``exclude_reference_from_observation``,
           ``exclude_reference_error_from_observation`` and ``exclude_velocity_from_observation`` environment arguments.

       The rest of the environment is the same as the original Ant environment.
       Below, the modified cost is described. For more information about the environment
       (e.g. observation space, action space, episode termination, etc.), please refer
       to the :gymnasium:`gymnasium library <environments/mujoco/ant>`.

   Modified cost:
       A cost, computed using the :meth:`AntCost.cost` method, is given for each
       simulation step, including the terminal step. This cost is defined as the error
       between the Ant's forward velocity and a reference value. A control
       cost and health penalty can also be included in the cost. The cost is computed as:

       .. math::

           cost = w_{forward\_velocity} \times (x_{velocity} - x_{reference\_x\_velocity})^2 + w_{ctrl} \times c_{ctrl} + p_{health}

   Solved Requirements:
       Considered solved when the average cost is less than or equal to 50 over
       100 consecutive trials.

   How to use:
       .. code-block:: python

           import stable_gym
           import gymnasium as gym
           env = gym.make("stable_gym:AntCost-v1")

   .. attribute:: state

      The current system state.

      :type: numpy.ndarray

   .. attribute:: dt

      The environment step size. Also available as :attr:`.tau`.

      :type: float

   .. attribute:: reference_forward_velocity

      The forward velocity that the agent should
      try to track.

      :type: float

   Initialise a new AntCost environment instance.

   :param reference_forward_velocity: The forward velocity that the
                                      agent should try to track. Defaults to ``1.0``.
   :type reference_forward_velocity: float, optional
   :param randomise_reference_forward_velocity: Whether to randomize
                                                the reference forward velocity. Defaults to ``False``.
   :type randomise_reference_forward_velocity: bool, optional
   :param randomise_reference_forward_velocity_range: The range of
                                                      the random reference forward velocity. Defaults to ``(0.5, 1.5)``.
   :type randomise_reference_forward_velocity_range: tuple, optional
   :param forward_velocity_weight: The weight used to scale the
                                   forward velocity error. Defaults to ``1.0``.
   :type forward_velocity_weight: float, optional
   :param include_ctrl_cost: Whether you also want to penalize the
                             ant if it takes actions that are too large. Defaults to ``False``.
   :type include_ctrl_cost: bool, optional
   :param include_health_penalty: Whether to penalize the ant if
                                  it becomes unhealthy (i.e. if it falls over). Defaults to ``True``.
   :type include_health_penalty: bool, optional
   :param health_penalty_size: The size of the unhealthy penalty.
                               Defaults to ``10``.
   :type health_penalty_size: int, optional
   :param ctrl_cost_weight: The weight used to scale the control
                            cost. Defaults to ``1e-4``.
   :type ctrl_cost_weight: float, optional
   :param use_contact_forces: Whether to include contact forces in
                              the observation and cost. Defaults to ``False``.
   :type use_contact_forces: bool, optional
   :param contact_cost_weight: The weight used to scale the contact
                               cost. Defaults to ``5e-4``.
   :type contact_cost_weight: float, optional
   :param terminate_when_unhealthy: Whether to terminate the episode
                                    when the ant becomes unhealthy. Defaults to ``True``.
   :type terminate_when_unhealthy: bool, optional
   :param healthy_z_range: The range of healthy z values. Defaults
                           to ``(0.2, 1.0)``.
   :type healthy_z_range: tuple, optional
   :param contact_force_range: The range of healthy contact forces.
                               Defaults to ``(-1.0, 1.0)``.
   :type contact_force_range: tuple, optional
   :param reset_noise_scale: Scale of random perturbations of the
                             initial position and velocity. Defaults to ``0.1``.
   :type reset_noise_scale: float, optional
   :param exclude_current_positions_from_observation: Whether to omit
                                                      the x- and y-coordinates of the front tip from observations. Excluding
                                                      the position can serve as an inductive bias to induce position-agnostic
                                                      behaviour in policies. Defaults to ``True``.
   :type exclude_current_positions_from_observation: bool, optional
   :param exclude_reference_from_observation: Whether the reference
                                              should be excluded from the observation. Defaults to ``False``.
   :type exclude_reference_from_observation: bool, optional
   :param exclude_reference_error_from_observation: Whether the error
                                                    should be excluded from the observation. Defaults to ``True``.
   :type exclude_reference_error_from_observation: bool, optional
   :param exclude_x_velocity_from_observation: Whether to omit the
                                               x- component of the velocity from observations. Defaults to ``False``.
   :type exclude_x_velocity_from_observation: bool, optional
   :param action_space_dtype: The data type of the
                              action space. Defaults to ``np.float32``.
   :type action_space_dtype: union[numpy.dtype, str], optional
   :param observation_space_dtype: The data type
                                   of the observation space. Defaults to ``np.float64``.
   :type observation_space_dtype: union[numpy.dtype, str], optional
   :param \*\*kwargs: Extra keyword arguments to pass to the
                      :class:`~gymnasium.envs.mujoco.ant_v4.AntEnv` class.

   .. py:property:: tau

      Alias for the environment step size. Done for compatibility with the
      other gymnasium environments.

   .. py:property:: t

      Environment time.

   .. py:property:: physics_time

      Returns the physics time.

   .. py:method:: cost(x_velocity, ctrl_cost)

      Compute the cost of a given x velocity and control cost.

      :param x_velocity: The Ant's x velocity.
      :type x_velocity: float
      :param ctrl_cost: The control cost.
      :type ctrl_cost: float

      :returns:

                tuple containing:

                    -   cost (float): The cost of the action.
                    -   info (:obj:`dict`): Additional information about the cost.
      :rtype: (tuple)


   .. py:method:: step(action)

      Take step into the environment.

      .. note::
          This method overrides the
          :meth:`~gymnasium.envs.mujoco.ant_v4.AntEnv.step` method
          such that the new cost function is used.

      :param action: Action to take in the environment.
      :type action: np.ndarray

      :returns:

                tuple containing:

                    -   obs (:obj:`np.ndarray`): Environment observation.
                    -   cost (:obj:`float`): Cost of the action.
                    -   terminated (:obj:`bool`): Whether the episode is terminated.
                    -   truncated (:obj:`bool`): Whether the episode was truncated. This
                        value is set by wrappers when for example a time limit is reached or
                        the agent goes out of bounds.
                    -   info (:obj:`dict`): Additional information about the environment.
      :rtype: (tuple)


   .. py:method:: reset(seed=None, options=None)

      Reset gymnasium environment.

      :param seed: A random seed for the environment. By default
                   ``None``.
      :type seed: int, optional
      :param options: A dictionary containing additional options for
                      resetting the environment. By default ``None``. Not used in this
                      environment.
      :type options: dict, optional

      :returns:

                tuple containing:

                    -   obs (:obj:`numpy.ndarray`): Initial environment observation.
                    -   info (:obj:`dict`): Dictionary containing additional information.
      :rtype: (tuple)



.. py:data:: env

   

